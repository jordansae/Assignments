{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aed67d76b742f360598b2c0f40b18b63",
     "grade": false,
     "grade_id": "cell-70c15471327b6620",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# COGS 108 - Assignment 5: Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e66894436102697439299c66c1e8a17e",
     "grade": false,
     "grade_id": "cell-8499cb794c95ec9d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Important\n",
    "- Rename this file to 'A5_$####.ipynb', replacing with your unique ID (first letter of your last name, followed by the last 4 digits of your student ID number), before you submit it. Submit it to TritonED.\n",
    "- This assignment has hidden tests: tests that are not visible here, but that will be run on your submitted assignment for grading.\n",
    "    - This means passing all the tests you can see in the notebook here does not guarantee you have the right answer!\n",
    "    - In particular many of the tests you can see simply check that the right variable names exist. Hidden tests check the actual values. \n",
    "        - It is up to you to check the values, and make sure they seem reasonable.\n",
    "- A reminder to restart the kernel and re-run the code as a first line check if things seem to go weird.\n",
    "    - For example, note that some cells can only be run once, because they re-write a variable (for example, your dataframe), and change it in a way that means a second execution will fail. \n",
    "    - Also, running some cells out of order might change the dataframe in ways that may cause an error, which can be fixed by re-running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0b10d6b48490820c1f1a3b07406400fd",
     "grade": false,
     "grade_id": "cell-6b464efd2fb5aabd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Background & Work Flow\n",
    "\n",
    "- In this homework assignment, we will be analyzing text data. A common approach to analyzing text data is to use methods that allow us to convert text data into some kind of numerical representation - since we can then use all of our mathematical tools on such data. In this assignment, we will explore 2 feature engineering methods that convert raw text data into numerical vectors:\n",
    "    - Bag of Words (BoW)\n",
    "        - BoW encodes an input sentence as the frequency of each word in the sentence. \n",
    "        - In this approach, all words contribute equally to the feature vectors.\n",
    "    - Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "        - TF-IDF is a measure of how important each term is to a specific document, as compared to an overall corpus. \n",
    "        - TF-IDF encodes a each word as the it's frequency in the document of interest, divided by a measure of how common the word is across all documents (the corpus).\n",
    "        - Using this approach each word contributes differently to the feature vectors.\n",
    "        - The assumption behind using TF-IDF is that words that appear commonly everywhere are not that informative about what is specifically interesting about a document of interest, so it is tuned to representing a document in terms of the words it uses that are different from other documents. \n",
    "\n",
    "- To compare those 2 methods, we will first apply them on the same Movie Review dataset to analyse sentiment (how positive or negative a text is). In order to make the comparison fair, the same SVM (support vector machine) classifier will be used to classify positive reviews and negative reviews.\n",
    "\n",
    "- SVM is a simple yet powerful and interpretable linear model. To use it as a classifier, we need to have at least 2 splits of the data: training data and test data. The training data is used to tune the weight parameters in the SVM to learn an optimal way to classify the training data. We can then test this trained SVM classifier on the test data, to see how well it works on data that the classifier has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff20ecd9199338a27728c1306d2c51d6",
     "grade": false,
     "grade_id": "Imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports - these are all the imports needed for the assignment\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import nltk package \n",
    "#   PennTreeBank word tokenizer \n",
    "#   English language stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# scikit-learn imports\n",
    "#   SVM (Support Vector Machine) classifer \n",
    "#   Vectorizer, which that transforms text data into bag-of-words feature\n",
    "#   TF-IDF Vectorizer that first removes widely used words in the dataset and then transforms test data\n",
    "#   Metrics functions to evaluate performance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d22183d219cc386a0cb84900e4711525",
     "grade": false,
     "grade_id": "cell-d96a6fcbdcbed177",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For this assignemnt we will be using nltk: the Natural Language Toolkit.\n",
    "\n",
    "To do so, we will need to download some text data.\n",
    "\n",
    "Natural language processing (NLP) often requires corpus data (lists of words, and or example text data) which is what we will download here now, if you don't already have them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the cell below, we will download some files from nltk. \n",
    "#   If you hit an error doing so, come back to this cell, and uncomment and run the code below. \n",
    "#   This code gives python permission to write to your disk (if it doesn't already have persmission to do so)\n",
    "\n",
    "# import ssl\n",
    "\n",
    "# try:\n",
    "#     _create_unverified_https_context = ssl._create_unverified_context\n",
    "# except AttributeError:\n",
    "#     pass\n",
    "# else:\n",
    "#     ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f82bd6229164ec98da8b4dc9a3bf25e",
     "grade": false,
     "grade_id": "cell-04e576aebbcdfe34",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Jordan\n",
      "[nltk_data]     Sae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jordan\n",
      "[nltk_data]     Sae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the NLTK English tokenizer and the stopwords of all languages\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2583e3b70af931e62b8094e488d28f30",
     "grade": false,
     "grade_id": "cell-c728326960d37d88",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1: Sentiment Analysis on Movie Review Data\n",
    "\n",
    "In part 1 we will apply sentiment analysis to Movie Review (MR) data.\n",
    "\n",
    "- The MR data contains more than 10,000 reviews collect from IMDB website, and each of the reviews is annotated as either positive or negative sample. The number of positive and negative reviews are roughly the same. For more information about the dataset, you can visit http://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "- For this homework assignment, we've already shuffled the data, and truncated the data to contain only 5000 reviews.\n",
    "\n",
    "In this part of the assignment we will:\n",
    "- Transform the raw text data into vectors with the BoW encoding method\n",
    "- Split the data into training and test sets\n",
    "- Write a function to train an SVM classifier on the training set\n",
    "- Test this classifier on the test set and report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2c277a3922d71b955a9b4d5093c55cfb",
     "grade": false,
     "grade_id": "Q-1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index label                                             review\n",
      "0      8477   neg  except as an acting exercise or an exceptional...\n",
      "1      4031   pos  japanese director shohei imamura 's latest fil...\n",
      "2     10240   neg  i walked away not really know who `` they `` w...\n",
      "3      8252   neg  what could have been a neat little story about...\n",
      "4      1346   pos  no screen fantasy-adventure in recent memory h...\n",
      "5      7385   neg      you can practically smell the patchouli oil .\n",
      "6      3632   pos  a mesmerizing cinematic poem from the first fr...\n",
      "7      6197   neg  has nothing good to speak about other than the...\n",
      "8      3843   pos  there 's very little sense to what 's going on...\n",
      "9      4098   pos  the cat 's meow marks a return to form for dir...\n",
      "10     1042   pos  it 's a lovely film with lovely performances b...\n",
      "11     7340   neg  the film flat lines when it should peak and is...\n",
      "12     6265   neg   if jews were catholics , this would be catechism\n",
      "13     7514   neg  a compendium of solondz 's own worst instincts...\n",
      "14     8833   neg  like an afterschool special with costumes by g...\n",
      "15     5289   pos  a pretty funny movie , with most of the humor ...\n",
      "16     5789   neg  just as the lousy tarantino imitations have su...\n",
      "17     9366   neg  gets the look and the period trappings right ,...\n",
      "18    10525   neg  the cinematic equivalent of patronizing a bar ...\n",
      "19     9863   neg  [ t ] he ideas of revolution # 9 are more comp...\n",
      "20     4838   pos  you need n't be steeped in '50s sociology , po...\n",
      "21     6025   neg  the plot grows thin soon , and you find yourse...\n",
      "22     8685   neg  an inexperienced director , mehta has much to ...\n",
      "23     4848   pos  works because we 're never sure if ohlinger 's...\n",
      "24      272   pos  münch 's genuine insight makes the film 's occ...\n",
      "25     7244   neg  late marriage 's stiffness is unlikely to demo...\n",
      "26     3615   pos                      a modestly surprising movie .\n",
      "27     7816   neg  feels like six different movies fighting each ...\n",
      "28     2553   pos  an uncomfortable movie , suffocating and somet...\n",
      "29     9703   neg  ultimately , clarity matters , both in breakin...\n",
      "...     ...   ...                                                ...\n",
      "4970   8029   neg  truth to tell , if you 've seen more than half...\n",
      "4971   4602   pos  late marriage is an in-your-face family drama ...\n",
      "4972   7807   neg        sometimes smart but more often sophomoric .\n",
      "4973   2038   pos     a stylistic romp that 's always fun to watch .\n",
      "4974   6789   neg  you can see the would-be surprises coming a mi...\n",
      "4975   8503   neg  unfortunately , a cast of competent performers...\n",
      "4976  10462   neg  a rehash of every gangster movie from the past...\n",
      "4977   9407   neg  worthless , from its pseudo-rock-video opening...\n",
      "4978   4803   pos  fresnadillo has something serious to say about...\n",
      "4979   2055   pos  clint eastwood 's blood work is a lot like a w...\n",
      "4980   6855   neg  less dizzying than just dizzy , the jaunt is p...\n",
      "4981   9369   neg                      a major waste . . . generic .\n",
      "4982    245   pos  you might not buy the ideas . but you 'll defi...\n",
      "4983   3170   pos  this is not chabrol 's best , but even his les...\n",
      "4984   5781   neg  this flat run at a hip-hop tootsie is so poorl...\n",
      "4985  10563   neg  no matter how much he runs around and acts lik...\n",
      "4986   7332   neg  scorsese does n't give us a character worth gi...\n",
      "4987   1956   pos  it 's hard to imagine anybody ever being `` in...\n",
      "4988   5834   neg  this is a fudged opportunity of gigantic propo...\n",
      "4989  10366   neg  no amount of burning , blasting , stabbing , a...\n",
      "4990     10   pos  this is a film well worth seeing , talking and...\n",
      "4991   9351   neg  distinctly sub-par . . . more likely to drown ...\n",
      "4992   4448   pos  the dirty jokes provide the funniest moments i...\n",
      "4993   6651   neg  do n't let the subtitles fool you ; the movie ...\n",
      "4994   9566   neg  mctiernan 's remake may be lighter on its feet...\n",
      "4995   1229   pos  pacino is brilliant as the sleep-deprived dorm...\n",
      "4996     70   pos         a taut , intelligent psychological drama .\n",
      "4997   9832   neg  ' . . . the cast portrays their cartoon counte...\n",
      "4998   9140   neg  the central character is n't complex enough to...\n",
      "4999   8507   neg  excruciatingly unfunny and pitifully unromantic .\n",
      "\n",
      "[5000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1a) Import data\n",
    "#  Import the textfile 'rt-polarity.txt' into a DataFrame called MR_df,\n",
    "#   Set the column names as 'index', 'label', 'review'\n",
    "# Note that 'rt-polarity.txt' is a tab separated raw text file, in which data is separated by tabs ('\\t')\n",
    "#   You can load this file with 'read_csv':\n",
    "#     Specifying the 'sep' (separator) argument as tabs ('\\t')\n",
    "#     You will have the set 'header' as None\n",
    "\n",
    "MR_filepath='data/rt-polarity.tsv'\n",
    "#YOUR CODE HERE\n",
    "MR_df = pd.read_csv(MR_filepath, names = ['index', 'label', 'review'], sep='\\t')\n",
    "print(MR_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1be01c42f731e39bfca476c20f7bb0d0",
     "grade": true,
     "grade_id": "A-1a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_df, pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "22306bbac34884ea61b62b1693ee4d9a",
     "grade": false,
     "grade_id": "cell-40dae07b7eed27b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review\n",
       "0   8477   neg  except as an acting exercise or an exceptional...\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...\n",
       "2  10240   neg  i walked away not really know who `` they `` w...\n",
       "3   8252   neg  what could have been a neat little story about...\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d2657c82ff17a400bef3d7c2b41c1f1c",
     "grade": false,
     "grade_id": "Q-1b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1b) Create a function that converts string labels to numerical labels\n",
    "#   Function name: convert_label\n",
    "#   The function should do the following:\n",
    "#     if the input label is \"pos\" return 1.0\n",
    "#     if the input label is \"neg\" return 0.0\n",
    "#     otherwise, return the input label as is\n",
    "\n",
    "#YOUR CODE HERE\n",
    "def convert_label(label):\n",
    "    if label in ['pos']:\n",
    "        output = 1.0\n",
    "        \n",
    "    elif label in ['neg']:\n",
    "        output = 0.0\n",
    "        \n",
    "    else:\n",
    "        output = label\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a93eeacd8bf8339f6ccaee9a0378b406",
     "grade": true,
     "grade_id": "A-1b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(convert_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6c5c0dc70d30e354596c74bfeafed99f",
     "grade": false,
     "grade_id": "Q-1c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index label                                             review    y\n",
      "0      8477   neg  except as an acting exercise or an exceptional...  0.0\n",
      "1      4031   pos  japanese director shohei imamura 's latest fil...  1.0\n",
      "2     10240   neg  i walked away not really know who `` they `` w...  0.0\n",
      "3      8252   neg  what could have been a neat little story about...  0.0\n",
      "4      1346   pos  no screen fantasy-adventure in recent memory h...  1.0\n",
      "5      7385   neg      you can practically smell the patchouli oil .  0.0\n",
      "6      3632   pos  a mesmerizing cinematic poem from the first fr...  1.0\n",
      "7      6197   neg  has nothing good to speak about other than the...  0.0\n",
      "8      3843   pos  there 's very little sense to what 's going on...  1.0\n",
      "9      4098   pos  the cat 's meow marks a return to form for dir...  1.0\n",
      "10     1042   pos  it 's a lovely film with lovely performances b...  1.0\n",
      "11     7340   neg  the film flat lines when it should peak and is...  0.0\n",
      "12     6265   neg   if jews were catholics , this would be catechism  0.0\n",
      "13     7514   neg  a compendium of solondz 's own worst instincts...  0.0\n",
      "14     8833   neg  like an afterschool special with costumes by g...  0.0\n",
      "15     5289   pos  a pretty funny movie , with most of the humor ...  1.0\n",
      "16     5789   neg  just as the lousy tarantino imitations have su...  0.0\n",
      "17     9366   neg  gets the look and the period trappings right ,...  0.0\n",
      "18    10525   neg  the cinematic equivalent of patronizing a bar ...  0.0\n",
      "19     9863   neg  [ t ] he ideas of revolution # 9 are more comp...  0.0\n",
      "20     4838   pos  you need n't be steeped in '50s sociology , po...  1.0\n",
      "21     6025   neg  the plot grows thin soon , and you find yourse...  0.0\n",
      "22     8685   neg  an inexperienced director , mehta has much to ...  0.0\n",
      "23     4848   pos  works because we 're never sure if ohlinger 's...  1.0\n",
      "24      272   pos  münch 's genuine insight makes the film 's occ...  1.0\n",
      "25     7244   neg  late marriage 's stiffness is unlikely to demo...  0.0\n",
      "26     3615   pos                      a modestly surprising movie .  1.0\n",
      "27     7816   neg  feels like six different movies fighting each ...  0.0\n",
      "28     2553   pos  an uncomfortable movie , suffocating and somet...  1.0\n",
      "29     9703   neg  ultimately , clarity matters , both in breakin...  0.0\n",
      "...     ...   ...                                                ...  ...\n",
      "4970   8029   neg  truth to tell , if you 've seen more than half...  0.0\n",
      "4971   4602   pos  late marriage is an in-your-face family drama ...  1.0\n",
      "4972   7807   neg        sometimes smart but more often sophomoric .  0.0\n",
      "4973   2038   pos     a stylistic romp that 's always fun to watch .  1.0\n",
      "4974   6789   neg  you can see the would-be surprises coming a mi...  0.0\n",
      "4975   8503   neg  unfortunately , a cast of competent performers...  0.0\n",
      "4976  10462   neg  a rehash of every gangster movie from the past...  0.0\n",
      "4977   9407   neg  worthless , from its pseudo-rock-video opening...  0.0\n",
      "4978   4803   pos  fresnadillo has something serious to say about...  1.0\n",
      "4979   2055   pos  clint eastwood 's blood work is a lot like a w...  1.0\n",
      "4980   6855   neg  less dizzying than just dizzy , the jaunt is p...  0.0\n",
      "4981   9369   neg                      a major waste . . . generic .  0.0\n",
      "4982    245   pos  you might not buy the ideas . but you 'll defi...  1.0\n",
      "4983   3170   pos  this is not chabrol 's best , but even his les...  1.0\n",
      "4984   5781   neg  this flat run at a hip-hop tootsie is so poorl...  0.0\n",
      "4985  10563   neg  no matter how much he runs around and acts lik...  0.0\n",
      "4986   7332   neg  scorsese does n't give us a character worth gi...  0.0\n",
      "4987   1956   pos  it 's hard to imagine anybody ever being `` in...  1.0\n",
      "4988   5834   neg  this is a fudged opportunity of gigantic propo...  0.0\n",
      "4989  10366   neg  no amount of burning , blasting , stabbing , a...  0.0\n",
      "4990     10   pos  this is a film well worth seeing , talking and...  1.0\n",
      "4991   9351   neg  distinctly sub-par . . . more likely to drown ...  0.0\n",
      "4992   4448   pos  the dirty jokes provide the funniest moments i...  1.0\n",
      "4993   6651   neg  do n't let the subtitles fool you ; the movie ...  0.0\n",
      "4994   9566   neg  mctiernan 's remake may be lighter on its feet...  0.0\n",
      "4995   1229   pos  pacino is brilliant as the sleep-deprived dorm...  1.0\n",
      "4996     70   pos         a taut , intelligent psychological drama .  1.0\n",
      "4997   9832   neg  ' . . . the cast portrays their cartoon counte...  0.0\n",
      "4998   9140   neg  the central character is n't complex enough to...  0.0\n",
      "4999   8507   neg  excruciatingly unfunny and pitifully unromantic .  0.0\n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1c) Convert all labels in MR_df[\"label\"] to numerical labels, using the 'convert_label' function\n",
    "#  Save them as a new column named \"y\" in MR_df\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_df['y'] = MR_df['label'].apply(convert_label)\n",
    "print(MR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4411b1a5943a1df885c3c8e948eb7b68",
     "grade": true,
     "grade_id": "A-1c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert sorted(set(MR_df['y'])) == [0., 1.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "851347cca7a104f450a70082311a2a1f",
     "grade": false,
     "grade_id": "cell-cd37ee3f688aaaec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8477</td>\n",
       "      <td>neg</td>\n",
       "      <td>except as an acting exercise or an exceptional...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4031</td>\n",
       "      <td>pos</td>\n",
       "      <td>japanese director shohei imamura 's latest fil...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240</td>\n",
       "      <td>neg</td>\n",
       "      <td>i walked away not really know who `` they `` w...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8252</td>\n",
       "      <td>neg</td>\n",
       "      <td>what could have been a neat little story about...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1346</td>\n",
       "      <td>pos</td>\n",
       "      <td>no screen fantasy-adventure in recent memory h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index label                                             review    y\n",
       "0   8477   neg  except as an acting exercise or an exceptional...  0.0\n",
       "1   4031   pos  japanese director shohei imamura 's latest fil...  1.0\n",
       "2  10240   neg  i walked away not really know who `` they `` w...  0.0\n",
       "3   8252   neg  what could have been a neat little story about...  0.0\n",
       "4   1346   pos  no screen fantasy-adventure in recent memory h...  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the MR_df data\n",
    "MR_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5c26081d88a7149416b3cfd66ca623a8",
     "grade": false,
     "grade_id": "Q-1d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1d) We will now create a \"CountVectorizer\" object to transform the text data into vectors with numerical values. \n",
    "#   To do so, we will initialize a \"CountVectorizer\" object, and name it as \"vectorizer\".\n",
    "\n",
    "# We need to pass 4 arguments to initialize a CountVectorizer:\n",
    "#   1. analyzer: 'word'\n",
    "#        Specify to analyze data from word-level\n",
    "#   2. max_features: 2000\n",
    "#        Set a max number of unique words\n",
    "#   3. tokenizer: word_tokenize\n",
    "#        Set to tokenize the text data by using the word_tokenizer from NLTK \n",
    "#   4. stop_words: stopwords.words('english')\n",
    "#        Set to remove all stopwords in English. \n",
    "#          We do this since they generally don't provide useful discriminative information.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vectorizer = CountVectorizer (analyzer = 'word', max_features = 2000, tokenizer = word_tokenize , stop_words = stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4a2bc9c2a6bc8e7c606c66eb1037ac3",
     "grade": true,
     "grade_id": "A-1d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert vectorizer.analyzer == 'word'\n",
    "assert vectorizer.max_features == 2000\n",
    "assert vectorizer.tokenizer == word_tokenize\n",
    "assert vectorizer.stop_words == stopwords.words('english')\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "83bae7fa828282a5590a4bb093fa8844",
     "grade": false,
     "grade_id": "Q-1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "(5000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# 1e) Transform reviews (MR_df[\"review\"]) into vectors using the \"vectorizer\" we created above:\n",
    "# The method you will be using is:\n",
    "#   MR_X = vectorizer.fit_transform(...).toarray()\n",
    "#   Note that we apply the 'toarray' method at the type cast the output to a numpy array. \n",
    "#     This is something we will do multiple times, to turn custom sklearn objects back into arrays. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_X = vectorizer.fit_transform(MR_df[\"review\"]).toarray()\n",
    "print(MR_X)\n",
    "print(MR_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec1fecbf168063a272cc960eac635ab4",
     "grade": true,
     "grade_id": "A-1e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(MR_X) == np.ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a91203e01aa7e842621473f8a2b6b63e",
     "grade": false,
     "grade_id": "Q-1f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "# 1f) Copy out \"y\" column in MR_df and save it as an np.ndarray named \"MR_y\"\n",
    "#   Make sure the shape of \"MR_y\" is (5000,) - you may have to use 'reshape' to do so. \n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_y = MR_df[\"y\"].values\n",
    "MR_X = vectorizer.fit_transform(MR_df['review']).toarray()\n",
    "print(MR_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3b15f7368fa336b9430b03d8f6988d63",
     "grade": true,
     "grade_id": "A-1f",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_y.shape == (5000,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1df2dee414dd910a9b2977172619f0a2",
     "grade": false,
     "grade_id": "Q-1g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# 1g) Split up train and test sets\n",
    "#   We first set 80% of the data as the training set to train an SVM classifier. \n",
    "#   We will then test the learnt classifier on the rest 20% data samples.\n",
    "\n",
    "# Calculate the number of training data samples (80% of total) and store it in \"num_training\"\n",
    "# Calculate the number of test data samples (20% of total) and store it in \"num_testing\"\n",
    "# Make sure both of these variables are of type 'int'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "num_training = int(MR_y.size * .8)\n",
    "num_testing = int(MR_y.size * .2)\n",
    "print(num_training)\n",
    "print(num_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c26caa14ff22dbcfc8f8888b2b98d6d",
     "grade": true,
     "grade_id": "A-1g",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(num_training) == int\n",
    "assert type(num_testing) == int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1ea2c7f40999ee2c94a2474c747ac65b",
     "grade": false,
     "grade_id": "Q-1h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[ 0.  1.  0. ...,  1.  1.  1.]\n",
      "[[0 1 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n",
      "[ 1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.\n",
      "  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.\n",
      "  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.\n",
      "  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.\n",
      "  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  0.\n",
      "  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  0.\n",
      "  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.\n",
      "  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.  0.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.\n",
      "  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.\n",
      "  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.]\n",
      "(4000, 2000)\n",
      "(4000,)\n",
      "(1000, 2000)\n",
      "(1000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# 1h) Split the \"MR_X\" and \"MR_y\" into training set and test set.\n",
    "#    You should use the 'num_training' variable to extract the data from MR_X and MR_y.\n",
    "#      Extract the first 'num_training' samples as training data, and extract the rest as test data.\n",
    "#  Name them as:\n",
    "#    \"MR_train_X\" and \"MR_train_y\" for the training set\n",
    "#    \"MR_test_X\" and \"MR_test_y\" for the test set\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_train_X = MR_X[:num_training, :]\n",
    "MR_train_y = MR_y[:num_training]\n",
    "MR_test_X = MR_X[num_training:, :]\n",
    "MR_test_y = MR_y[num_training:]\n",
    "print(MR_train_X)\n",
    "print(MR_train_y)\n",
    "print(MR_test_X)\n",
    "print(MR_test_y)\n",
    "print(MR_train_X.shape)\n",
    "print(MR_train_y.shape)\n",
    "print(MR_test_X.shape)\n",
    "print(MR_test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "394846299466a6fc67650c96a45664e7",
     "grade": true,
     "grade_id": "A-1h",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_train_X.shape[0] == MR_train_y.shape[0]\n",
    "assert MR_test_X.shape[0] == MR_test_y.shape[0]\n",
    "\n",
    "assert len(MR_train_X) == 4000\n",
    "assert len(MR_test_y) == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9d7c1b2673df0341154608065250257b",
     "grade": false,
     "grade_id": "Q-1i",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1i) Define a function called \"train_SVM\" that initializes an SVM classifier and trains it\n",
    "# \n",
    "# Inputs: \n",
    "#     X: np.ndarray, training samples, \n",
    "#     y: np.ndarray, training labels,\n",
    "#     kernel: string, set the default value of \"kernel\" as \"linear\"\n",
    "# Output:\n",
    "#     a trained classifier \"clf\"\n",
    "\n",
    "# Hint: There are 2 steps involved in this function:\n",
    "#     1) Initializing an SVM classifier: clf = SVC(...)\n",
    "#     2) Training the classifier: clf.fit(X, y)\n",
    "\n",
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf = SVC(kernel = kernel)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "55eb758d448afee6160529b9960da8ac",
     "grade": true,
     "grade_id": "A-1i",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert callable(train_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "288d59a7b0e00aac80a56fb85cac91ef",
     "grade": false,
     "grade_id": "Q-ij",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1j) Train an SVM classifier on the samples \"MR_train_X\" and the labels \"MR_train_y\"\n",
    "#  You need to call the function \"train_SVM\" you just created.\n",
    "#  Name the returned object as \"MR_clf\"\n",
    "#  Note that running this function may take many seconds / up to a few minutes to run.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_clf = train_SVM(MR_train_X, MR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d527fd33a6355256100c77d493ffec4e",
     "grade": true,
     "grade_id": "A-ij",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f7c73a6193612466d612ce1d439f2de3",
     "grade": false,
     "grade_id": "Q-k",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1k) predict labels for both training samples and test samples\n",
    "# You will need to use \n",
    "#    MR_clf.predict(...)\n",
    "\n",
    "# Name the predicted labels for the training samples as \"MR_predicted_train_y\"\n",
    "# Name the predicted labels for the testing samples as \"MR_predicted_test_y\" \n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_X = vectorizer.fit_transform(MR_df['review']).toarray()\n",
    "MR_predicted_train_y = MR_clf.predict(MR_train_X)\n",
    "MR_predicted_test_y = MR_clf.predict(MR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "975855c61de091efe8eb52181efc8e80",
     "grade": false,
     "grade_id": "cell-fc5799e344e24b69",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.92      0.91      2008\n",
      "        1.0       0.92      0.91      0.91      1992\n",
      "\n",
      "avg / total       0.91      0.91      0.91      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we will use the function 'classification_report'\n",
    "#  to print out the performance of the classifier on the training set\n",
    "\n",
    "# Your classifier should be able to reach above 90% accuracy on the training set\n",
    "print(classification_report(MR_train_y,MR_predicted_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c836592afff80898804c801bd2e21d6a",
     "grade": true,
     "grade_id": "A-1k",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 1k\n",
    "assert MR_predicted_train_y.shape == (4000,)\n",
    "assert MR_predicted_test_y.shape == (1000,)\n",
    "\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_y,MR_predicted_train_y)\n",
    "assert np.isclose(precision[0], 0.91, 0.02)\n",
    "assert np.isclose(precision[1], 0.92, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab144d1f5f428088d3dbb25acfd27bf5",
     "grade": false,
     "grade_id": "cell-9fc925527bb32076",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      0.68      0.69       482\n",
      "        1.0       0.71      0.72      0.72       518\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And finally, we check the performance of the trained classifier on the test set\n",
    "\n",
    "# Your classifier should be able to reach around 70% accuracy on the test set.\n",
    "print(classification_report(MR_test_y, MR_predicted_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "592f6be991c7a20c59314ff39989da9b",
     "grade": false,
     "grade_id": "cell-1f649bb709859c3e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2: TF-IDF\n",
    "\n",
    "In this part, we will explore TF-IDF on sentiment analysis.\n",
    "\n",
    "TF-IDF is used as an alternate way to encode text data, as compared to the BoW's approach used in Part 1. \n",
    "\n",
    "To do, we will:\n",
    "- Transform the raw text data into vectors using TF-IDF\n",
    "- Train an SVM classifier on the training set and report the performance this classifer on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "faa48862931ed6e645211193b93d5d68",
     "grade": false,
     "grade_id": "Q-2a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2a) We will create a \"TfidfVectorizer\" object to transform the text data into vectors with TF-IDF\n",
    "#\n",
    "# To do so, we will initialize a \"TfidfVectorizer\" object, and name it as \"tfidf\".\n",
    "#\n",
    "# We need to pass 4 arguments into the \"TfidfVectorizer\" to initialize a \"tfidf\":\n",
    "#   1. sublinear_tf: True\n",
    "#        Set to apply TF scaling.\n",
    "#   2. analyzer: 'word'\n",
    "#        Set to analyze the data at the word-level\n",
    "#   3. max_features: 2000\n",
    "#        Set the max number of unique words\n",
    "#   4. tokenizer: word_tokenize\n",
    "#        Set to tokenize the text data by using the word_tokenizer from NLTK \n",
    "\n",
    "# YOUR CODE HERE\n",
    "tfidf = TfidfVectorizer (sublinear_tf = True, analyzer = 'word', max_features = 2000, tokenizer = word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d607d89e0d3ffcece40dd78cccb5a55",
     "grade": true,
     "grade_id": "A-2a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert tfidf.analyzer == 'word'\n",
    "assert tfidf.max_features == 2000\n",
    "assert tfidf.tokenizer == word_tokenize\n",
    "assert tfidf.stop_words == None\n",
    "assert hasattr(vectorizer, \"fit_transform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "10a2567372b9ee91453dcacf8d6b9161",
     "grade": false,
     "grade_id": "Q-2b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# 2b) Transform Reviews \n",
    "# Transform the 'review' column of MR_df into vectors using the \"tfidf\" we created above.\n",
    "#   Save the transformed data into a variable called \"MR_tfidf_X\"\n",
    "# Hint: You might need to cast the datatype of \"MR_tfidf_X\" to numpy.ndarray by using .toarray()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_tfidf_X = tfidf.fit_transform(MR_df[\"review\"]).toarray()\n",
    "print(MR_tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e419cca933997eed3404edc0224a311",
     "grade": true,
     "grade_id": "A-2b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_tfidf_X, np.ndarray)\n",
    "\n",
    "assert \"skills\" in set(tfidf.stop_words_)\n",
    "assert \"risky\" in set(tfidf.stop_words_)\n",
    "assert \"adopts\" in set(tfidf.stop_words_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9657b973067f86378387379120e2a63a",
     "grade": false,
     "grade_id": "Q-2c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(4000, 2000)\n",
      "[ 0.  1.  0. ...,  1.  1.  1.]\n",
      "(4000,)\n",
      "[[ 0.          0.28956344  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.        ]]\n",
      "(1000, 2000)\n",
      "[ 1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.\n",
      "  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.\n",
      "  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.\n",
      "  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.\n",
      "  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  0.\n",
      "  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.  1.\n",
      "  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  1.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.\n",
      "  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  0.\n",
      "  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  1.\n",
      "  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
      "  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.  1.  1.\n",
      "  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.  0.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.\n",
      "  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.\n",
      "  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# 2c) Split the \"MR_tfidf_X\" and \"MR_y\" into training set and test set. \n",
    "#  Name these variables as:\n",
    "#    \"MR_train_tfidf_X\" and \"MR_train_tfidf_y\" for the training set\n",
    "#    \"MR_test_tfidf_X\" and \"MR_test_tfidf_y\" for the test set\n",
    "#  We will use the same 80/20 split as in part 1. \n",
    "#    You can use the same 'num_training' variable from part 1 to split up the data.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_train_tfidf_X = MR_tfidf_X[:num_training, :]\n",
    "MR_train_tfidf_y = MR_y[:num_training]\n",
    "MR_test_tfidf_X = MR_tfidf_X[num_training:, :]\n",
    "MR_test_tfidf_y = MR_y[num_training:]\n",
    "print(MR_train_tfidf_X)\n",
    "print(MR_train_tfidf_X.shape)\n",
    "print(MR_train_tfidf_y)\n",
    "print(MR_train_tfidf_y.shape)\n",
    "print(MR_test_tfidf_X)\n",
    "print(MR_test_tfidf_X.shape)\n",
    "print(MR_test_tfidf_y)\n",
    "print(MR_test_tfidf_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6e5d24c12ad756d5ec0d4e12e0fa7e7",
     "grade": true,
     "grade_id": "A-2c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert MR_train_tfidf_X[0].tolist() == MR_tfidf_X[0].tolist()\n",
    "assert MR_train_tfidf_X.shape == (4000, 2000)\n",
    "assert MR_test_tfidf_X.shape == (1000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e4d0041012fd0bbe591ca2649a957557",
     "grade": false,
     "grade_id": "Q-2d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2d) Train an SVM classifier on the samples \"MR_train_tfidf_X\" and the labels \"MR_train_y\"\n",
    "#   You need to call the function \"train_SVM\" you created in part 1.\n",
    "#   Name the returned object as \"MR_tfidf_clf\".\n",
    "#   Note that this may take many seconds, up to a few minutes, to run.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_tfidf_clf = train_SVM(MR_train_tfidf_X, MR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb5d311cc8b088971b1b20fd1e14301f",
     "grade": true,
     "grade_id": "A-2d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(MR_clf, SVC)\n",
    "assert hasattr(MR_tfidf_clf, \"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f08dc4dc22da4302291c1034c8bb563c",
     "grade": false,
     "grade_id": "Q-2e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2e) Predict the labels for both the training and test samples (the 'X' data)\n",
    "# You will need to use \n",
    "#    MR_tfidf_clf.predict(...)\n",
    "\n",
    "# Name the predicted labels on training samples as \"MR_pred_train_tfidf_y\"\n",
    "# Name the predicted labels on testing samples as \"MR_pred_test_tfidf_y\" \n",
    "\n",
    "# YOUR CODE HERE\n",
    "MR_pred_train_tfidf_y = MR_tfidf_clf.predict(MR_train_tfidf_X)\n",
    "MR_pred_test_tfidf_y = MR_tfidf_clf.predict(MR_test_tfidf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e435a2f2352cca1073ce66f4a7bfa4d7",
     "grade": false,
     "grade_id": "cell-afa1a0e6e8f72a98",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.88      0.87      2008\n",
      "        1.0       0.87      0.85      0.86      1992\n",
      "\n",
      "avg / total       0.87      0.87      0.87      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Again, we use 'classification_report' to check the performance on the training set \n",
    "\n",
    "# Your classifier should be able to reach above 85% accuracy.\n",
    "print(classification_report(MR_train_tfidf_y, MR_pred_train_tfidf_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8aa3a7db72cd3b5a8208c12fb4e35124",
     "grade": true,
     "grade_id": "A-2e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 2e\n",
    "precision, recall, _, _ = precision_recall_fscore_support(MR_train_tfidf_y, MR_pred_train_tfidf_y)\n",
    "assert np.isclose(precision[0], 0.86, 0.02)\n",
    "assert np.isclose(precision[1], 0.87, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "577fe1deb6fd1b240c0e02a4c08c36a0",
     "grade": false,
     "grade_id": "cell-0d6895d998434cbe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.72      0.72       482\n",
      "        1.0       0.74      0.74      0.74       518\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And check performance on the test set\n",
    "\n",
    "# Your classifier should be able to reach around 70% accuracy.\n",
    "print(classification_report(MR_test_tfidf_y, MR_pred_test_tfidf_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "972dbe682b12f7e0afb0c36f5ef3214f",
     "grade": false,
     "grade_id": "cell-29e222dd4865bd30",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Written Answer Question\n",
    "\n",
    "How does the performance of the TF-IDF classifier compare to the classifier used in part 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e0127d55bda50552dcea96a26fdeef27",
     "grade": true,
     "grade_id": "cell-ac993b2591707522",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The classifier in Part 1 initially took in the strings and converted them to values. Then it it compared the SVM function and got above a 90% on the training set and above a 70% on the testing set. The classifier in Part 2 took the tfidf and the original and compared it to one another, reaching above an 85% on the tfidf data and above a 70% on the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b62782d33e5022d26d18ec60b5a457f",
     "grade": false,
     "grade_id": "cell-15bf17c90c32702a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 3: Sentiment Analysis on Customer Review with TF-IDF\n",
    "\n",
    "In this part, we will use TF-IDF to analyse the sentiment of some Customer Review (CR) data.\n",
    "\n",
    "The CR data contains around 3771 reviews, and they were all collected from the Amazon website. The reviews are annotated by human as either positive reviews and negative reviews. In this dataset, the 2 classes are not balanced, as there are twice as many positive reviews as negative reviews.\n",
    "\n",
    "For more information on this dataset, you can visit https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n",
    "\n",
    "In this part, we have alreay split the data into a training set and a test set, in which the training set has labels for the reviews, but the test set doesn't. \n",
    "\n",
    "The goal is to train an SVM classifier on the training set, and then predict pos/neg for each review in the test set.\n",
    "\n",
    "To do so, we will:\n",
    "- Use the TF-IDF feature engineering method to encode the raw text data into vectors\n",
    "- Train an SVM classifier on the training set\n",
    "- Predict labels for the reviews in the test set\n",
    "\n",
    "The performance of your trained classifier on the test set will be checked by a hidden test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "68aa92ffa58e05665fec75a92ecdd002",
     "grade": false,
     "grade_id": "Q-3a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index label                                             review\n",
      "0       646   pos  but i 've already emailed creative tech suppor...\n",
      "1      2910   neg        5 . the zen does not have a stop button ! .\n",
      "2        49   pos  the progressive scan option can be turned off ...\n",
      "3      3427   neg       my old sony ericsson t610 has this feature .\n",
      "4      2792   neg  quite simply , the firmware and / or the os th...\n",
      "5       311   pos  if you strictly use the lcd and not the view f...\n",
      "6       848   pos  i thought i 'd have to buy a set of headphones...\n",
      "7      3720   neg  although i disabled norton antispam , it is st...\n",
      "8      2105   pos  it is amazing that the battery lasts so long w...\n",
      "9      3021   neg  i find the major problem with this item is tha...\n",
      "10     3538   neg  - no option for caller-id pictures or individu...\n",
      "11     1442   pos  also , the wma compression format is superior ...\n",
      "12     2315   pos  also included in the `` games `` section is th...\n",
      "13     1157   pos       i would put the hitachi up with the best ! .\n",
      "14      191   pos  i recommend unreservedly the powershot g3 to a...\n",
      "15     1730   pos  even at the `` normal `` setting , a 8x10 prin...\n",
      "16      247   pos  3 . the remote capture and file viewer softwar...\n",
      "17     1453   pos                            - replaceable battery .\n",
      "18     1557   pos  i bought my zen micro three months ago mainly ...\n",
      "19     1045   pos  the champ did not start letting a little odor ...\n",
      "20     2827   neg  2 ) no games - it has a cool screen - why not ...\n",
      "21     1240   pos                  it doesn 't bog down under load .\n",
      "22     1109   pos  the thought of not having to buy refills and j...\n",
      "23     2559   neg  only owned it about two weeks so i expect we '...\n",
      "24      683   pos  the player 's software is very easy to use and...\n",
      "25     2032   pos  another great feature for me anyway is the abi...\n",
      "26     3682   neg  even though i have the parental controls off i...\n",
      "27      684   pos  compared to musicmatch , the software has a be...\n",
      "28      192   pos  it gives great pictures , the controls are eas...\n",
      "29     1514   pos  fm transmitter ( belkin has a good one ) to us...\n",
      "...     ...   ...                                                ...\n",
      "2986   1130   pos  the hitachi has plenty of power , runs smooth ...\n",
      "2987    584   pos  i had no problems following their installation...\n",
      "2988   3641   neg  norton internet security 2004 is one of the mo...\n",
      "2989    830   pos  file transfers are fast , nearly a song per se...\n",
      "2990   1754   pos                       this is a wonderful camera .\n",
      "2991    714   pos  i received this item for christmas and it has ...\n",
      "2992   1058   pos  it doesn 't stink , ever ( like some have assu...\n",
      "2993   1363   pos  purchased this router a few months back , no p...\n",
      "2994   1359   pos  i am getting better speeds on all my web progr...\n",
      "2995     31   pos                     even viewed cds full of jogs .\n",
      "2996   3432   neg  2- it is bulky and the small buttons on the si...\n",
      "2997   1095   pos                   excellent diaper disposal unit .\n",
      "2998   3733   neg  after 10 years , i now downloaded mccaffee 's ...\n",
      "2999   3514   neg                  i am bored with the silver look .\n",
      "3000    803   pos  the zen is an outstanding way to shuttle music...\n",
      "3001    381   pos  i tell you now , after lot of shooting in many...\n",
      "3002   1811   pos  the picture quality is amazing and you can con...\n",
      "3003    679   pos                 i love the storage in this thing .\n",
      "3004   2104   pos  i 've used the speakerphone for almost two hou...\n",
      "3005   1393   pos  the sound is great , the portability , etc . ....\n",
      "3006   1879   pos  what makes it so great is the versatility and ...\n",
      "3007   2911   neg  but this is * not documented * in the zen manu...\n",
      "3008   1969   pos  the camera is adequate and if i want high-res ...\n",
      "3009   3292   neg  after research of other creative hard drive pl...\n",
      "3010   1974   pos  for those mac osx users out there , isync work...\n",
      "3011   2720   neg  i 'd give it 5 stars if the automatic modes we...\n",
      "3012    986   pos  the container is hard to open , which is exact...\n",
      "3013   2309   pos  the design , as mentioned above , is sleek , c...\n",
      "3014   3315   neg                        unfortunately i was wrong .\n",
      "3015   2767   neg  the explorer program did shut down a couple ti...\n",
      "\n",
      "[3016 rows x 3 columns]\n",
      "     index                                             review\n",
      "0     3546                                        its quiet .\n",
      "1     3232  overall , it does its basic function very well...\n",
      "2      979  i love that you don 't have to purchase expens...\n",
      "3      372  i bought this camera two days ago , and i 'm v...\n",
      "4     3278  it barely holds anything and mine just puts a ...\n",
      "5     3683  now in october , 2004 , the firewall said i co...\n",
      "6      742                  lastly , the price is fantastic :\n",
      "7     3471  these people takes lest effort to process reba...\n",
      "8     1509  i compared it to other cd players ( two models...\n",
      "9     1079               i have never had an odor problem ! .\n",
      "10    3753  buy this if you like mental challenges or tryi...\n",
      "11     581  the screen is very easy to read and the blue l...\n",
      "12    3589  first , let me say that i got the 20gb ipod fo...\n",
      "13    2563  5 ) this apex model 2600 will not work with my...\n",
      "14     419  neat feature for self-timer allows you to reco...\n",
      "15    2133                   the phone is very light weight .\n",
      "16    2240       this phone is highly recommended otherwise .\n",
      "17    1605  pros the design is very nice , and the colors ...\n",
      "18     895  i felt better with this one since it had the s...\n",
      "19    3101  it 's oftentimes hard to get a good grip on th...\n",
      "20    1724  nikon 4300 , i feel , is the best camera out t...\n",
      "21    1771  the small size is perfect for my little hands ...\n",
      "22    3400     even the instruction booklet is out of order .\n",
      "23    3185  so , you might inquire , why don 't they make ...\n",
      "24     787      oh . . . and file transfers are fast & easy .\n",
      "25     616  i have over 2000 files in my playlist at the m...\n",
      "26    3341  now , the player 's ear phone jack is not work...\n",
      "27    1773  it really is an awesome camera that is hard to...\n",
      "28    3096  that said , i am disappointed in the plunging ...\n",
      "29    2771  i 've tried the belkin fm transmitter unit wit...\n",
      "..     ...                                                ...\n",
      "725   1761  if you have to buy a camera on a bu get , this...\n",
      "726   1512             fits well in hand in trouser pockets .\n",
      "727    771  it 's small , light and nice looking and the d...\n",
      "728   3711  then , my ad/pop-up blocking was completely go...\n",
      "729    248  4 . the shape of this device is a little squar...\n",
      "730    891  7 ) some people have problems with the flip sw...\n",
      "731   2249  sound quality : the ipod 's sound quality is p...\n",
      "732   2346                                way to go apple ! .\n",
      "733   1195                        smooth plunging mechanism .\n",
      "734   2556  the front door is miss aligned on my unit and ...\n",
      "735   1484                             the sound is amazing .\n",
      "736   3769  this time , it started the installation proces...\n",
      "737   2727        only 1 problem , no accessories . . . yet .\n",
      "738   3738  to install that version you have to uninstall ...\n",
      "739   1505  built in microphone is great for recording sho...\n",
      "740   1395  creative did well on its rechargeable battery ...\n",
      "741   3226  limitations : - not a lot of original accessor...\n",
      "742    688                          1 ) price / gb of storage\n",
      "743   1305  just follow the instructions carefully , it 's...\n",
      "744   1869  handsfree future is good , but not too exciting .\n",
      "745    890  12 ) big storage - my entire cd collection in ...\n",
      "746   1820    2 it is easy enough for my grandmother to use .\n",
      "747   2840                       controls are a bit awkward .\n",
      "748   1330  the documentation is much better than the docu...\n",
      "749   1935  nokia makes great phones , and this one is the...\n",
      "750   2529        after two weeks the picture kept freezing .\n",
      "751    827                                * removable battery\n",
      "752   3581  but i had to give you four because the service...\n",
      "753    215                           takes excellent photos .\n",
      "754    503  first , it really is tiny ; . the size of a pa...\n",
      "\n",
      "[755 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3a) Loading the data\n",
    "\n",
    "# Customer review task has 2 files\n",
    "#  \"data/custrev.tsv\" contains training data with labels\n",
    "#  \"data/custrev.tsv\" contains test data without labels which need to be predicted \n",
    "# Import raw textfile 'data/custrev.train' into a DataFrame called CR_train_df,\n",
    "#   Set the column names as 'index', 'label', 'review'\n",
    "# Import raw textfile 'data/custrev.test' into a DataFrame called CR_test_df,\n",
    "#   Set the column names as 'index', 'review'\n",
    "# Note that both will need to be imported with 'sep' and 'header' arguments (like in 1a)\n",
    "\n",
    "CR_train_file='data/custrev_train.tsv'\n",
    "CR_test_file = 'data/custrev_test.tsv'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_train_df = pd.read_csv(CR_train_file, names = ['index', 'label', 'review'], sep='\\t')\n",
    "CR_test_df = pd.read_csv(CR_test_file, names = ['index', 'review'], sep='\\t')\n",
    "print(CR_train_df)\n",
    "print(CR_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb79643d0607409171e2bc597c736d5d",
     "grade": true,
     "grade_id": "A-3a",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_train_df, pd.DataFrame)\n",
    "assert isinstance(CR_test_df, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fd89493c35c043d1923aeebcc420a340",
     "grade": false,
     "grade_id": "Q-3b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index label                                             review\n",
      "0      646   pos  but i 've already emailed creative tech suppor...\n",
      "1     2910   neg        5 . the zen does not have a stop button ! .\n",
      "2       49   pos  the progressive scan option can be turned off ...\n",
      "3     3427   neg       my old sony ericsson t610 has this feature .\n",
      "4     2792   neg  quite simply , the firmware and / or the os th...\n",
      "5      311   pos  if you strictly use the lcd and not the view f...\n",
      "6      848   pos  i thought i 'd have to buy a set of headphones...\n",
      "7     3720   neg  although i disabled norton antispam , it is st...\n",
      "8     2105   pos  it is amazing that the battery lasts so long w...\n",
      "9     3021   neg  i find the major problem with this item is tha...\n",
      "10    3538   neg  - no option for caller-id pictures or individu...\n",
      "11    1442   pos  also , the wma compression format is superior ...\n",
      "12    2315   pos  also included in the `` games `` section is th...\n",
      "13    1157   pos       i would put the hitachi up with the best ! .\n",
      "14     191   pos  i recommend unreservedly the powershot g3 to a...\n",
      "15    1730   pos  even at the `` normal `` setting , a 8x10 prin...\n",
      "16     247   pos  3 . the remote capture and file viewer softwar...\n",
      "17    1453   pos                            - replaceable battery .\n",
      "18    1557   pos  i bought my zen micro three months ago mainly ...\n",
      "19    1045   pos  the champ did not start letting a little odor ...\n",
      "20    2827   neg  2 ) no games - it has a cool screen - why not ...\n",
      "21    1240   pos                  it doesn 't bog down under load .\n",
      "22    1109   pos  the thought of not having to buy refills and j...\n",
      "23    2559   neg  only owned it about two weeks so i expect we '...\n",
      "24     683   pos  the player 's software is very easy to use and...\n",
      "25    2032   pos  another great feature for me anyway is the abi...\n",
      "26    3682   neg  even though i have the parental controls off i...\n",
      "27     684   pos  compared to musicmatch , the software has a be...\n",
      "28     192   pos  it gives great pictures , the controls are eas...\n",
      "29    1514   pos  fm transmitter ( belkin has a good one ) to us...\n",
      "..     ...   ...                                                ...\n",
      "725   1761   NaN  if you have to buy a camera on a bu get , this...\n",
      "726   1512   NaN             fits well in hand in trouser pockets .\n",
      "727    771   NaN  it 's small , light and nice looking and the d...\n",
      "728   3711   NaN  then , my ad/pop-up blocking was completely go...\n",
      "729    248   NaN  4 . the shape of this device is a little squar...\n",
      "730    891   NaN  7 ) some people have problems with the flip sw...\n",
      "731   2249   NaN  sound quality : the ipod 's sound quality is p...\n",
      "732   2346   NaN                                way to go apple ! .\n",
      "733   1195   NaN                        smooth plunging mechanism .\n",
      "734   2556   NaN  the front door is miss aligned on my unit and ...\n",
      "735   1484   NaN                             the sound is amazing .\n",
      "736   3769   NaN  this time , it started the installation proces...\n",
      "737   2727   NaN        only 1 problem , no accessories . . . yet .\n",
      "738   3738   NaN  to install that version you have to uninstall ...\n",
      "739   1505   NaN  built in microphone is great for recording sho...\n",
      "740   1395   NaN  creative did well on its rechargeable battery ...\n",
      "741   3226   NaN  limitations : - not a lot of original accessor...\n",
      "742    688   NaN                          1 ) price / gb of storage\n",
      "743   1305   NaN  just follow the instructions carefully , it 's...\n",
      "744   1869   NaN  handsfree future is good , but not too exciting .\n",
      "745    890   NaN  12 ) big storage - my entire cd collection in ...\n",
      "746   1820   NaN    2 it is easy enough for my grandmother to use .\n",
      "747   2840   NaN                       controls are a bit awkward .\n",
      "748   1330   NaN  the documentation is much better than the docu...\n",
      "749   1935   NaN  nokia makes great phones , and this one is the...\n",
      "750   2529   NaN        after two weeks the picture kept freezing .\n",
      "751    827   NaN                                * removable battery\n",
      "752   3581   NaN  but i had to give you four because the service...\n",
      "753    215   NaN                           takes excellent photos .\n",
      "754    503   NaN  first , it really is tiny ; . the size of a pa...\n",
      "\n",
      "[3771 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3b) Concatenate 2 DataFrames into 1 DataFrame, and name it \"CR_df\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_df = pd.concat([CR_train_df, CR_test_df])\n",
    "print(CR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f9c92dcaf4b13595f046a6f831dbe0e",
     "grade": true,
     "grade_id": "A-3b",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(CR_df) == 3771\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4c6e09491f375bd27401754be95e75dd",
     "grade": false,
     "grade_id": "Q-3c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index label                                             review    y\n",
      "0      646   pos  but i 've already emailed creative tech suppor...  1.0\n",
      "1     2910   neg        5 . the zen does not have a stop button ! .  0.0\n",
      "2       49   pos  the progressive scan option can be turned off ...  1.0\n",
      "3     3427   neg       my old sony ericsson t610 has this feature .  0.0\n",
      "4     2792   neg  quite simply , the firmware and / or the os th...  0.0\n",
      "5      311   pos  if you strictly use the lcd and not the view f...  1.0\n",
      "6      848   pos  i thought i 'd have to buy a set of headphones...  1.0\n",
      "7     3720   neg  although i disabled norton antispam , it is st...  0.0\n",
      "8     2105   pos  it is amazing that the battery lasts so long w...  1.0\n",
      "9     3021   neg  i find the major problem with this item is tha...  0.0\n",
      "10    3538   neg  - no option for caller-id pictures or individu...  0.0\n",
      "11    1442   pos  also , the wma compression format is superior ...  1.0\n",
      "12    2315   pos  also included in the `` games `` section is th...  1.0\n",
      "13    1157   pos       i would put the hitachi up with the best ! .  1.0\n",
      "14     191   pos  i recommend unreservedly the powershot g3 to a...  1.0\n",
      "15    1730   pos  even at the `` normal `` setting , a 8x10 prin...  1.0\n",
      "16     247   pos  3 . the remote capture and file viewer softwar...  1.0\n",
      "17    1453   pos                            - replaceable battery .  1.0\n",
      "18    1557   pos  i bought my zen micro three months ago mainly ...  1.0\n",
      "19    1045   pos  the champ did not start letting a little odor ...  1.0\n",
      "20    2827   neg  2 ) no games - it has a cool screen - why not ...  0.0\n",
      "21    1240   pos                  it doesn 't bog down under load .  1.0\n",
      "22    1109   pos  the thought of not having to buy refills and j...  1.0\n",
      "23    2559   neg  only owned it about two weeks so i expect we '...  0.0\n",
      "24     683   pos  the player 's software is very easy to use and...  1.0\n",
      "25    2032   pos  another great feature for me anyway is the abi...  1.0\n",
      "26    3682   neg  even though i have the parental controls off i...  0.0\n",
      "27     684   pos  compared to musicmatch , the software has a be...  1.0\n",
      "28     192   pos  it gives great pictures , the controls are eas...  1.0\n",
      "29    1514   pos  fm transmitter ( belkin has a good one ) to us...  1.0\n",
      "..     ...   ...                                                ...  ...\n",
      "725   1761   NaN  if you have to buy a camera on a bu get , this...  NaN\n",
      "726   1512   NaN             fits well in hand in trouser pockets .  NaN\n",
      "727    771   NaN  it 's small , light and nice looking and the d...  NaN\n",
      "728   3711   NaN  then , my ad/pop-up blocking was completely go...  NaN\n",
      "729    248   NaN  4 . the shape of this device is a little squar...  NaN\n",
      "730    891   NaN  7 ) some people have problems with the flip sw...  NaN\n",
      "731   2249   NaN  sound quality : the ipod 's sound quality is p...  NaN\n",
      "732   2346   NaN                                way to go apple ! .  NaN\n",
      "733   1195   NaN                        smooth plunging mechanism .  NaN\n",
      "734   2556   NaN  the front door is miss aligned on my unit and ...  NaN\n",
      "735   1484   NaN                             the sound is amazing .  NaN\n",
      "736   3769   NaN  this time , it started the installation proces...  NaN\n",
      "737   2727   NaN        only 1 problem , no accessories . . . yet .  NaN\n",
      "738   3738   NaN  to install that version you have to uninstall ...  NaN\n",
      "739   1505   NaN  built in microphone is great for recording sho...  NaN\n",
      "740   1395   NaN  creative did well on its rechargeable battery ...  NaN\n",
      "741   3226   NaN  limitations : - not a lot of original accessor...  NaN\n",
      "742    688   NaN                          1 ) price / gb of storage  NaN\n",
      "743   1305   NaN  just follow the instructions carefully , it 's...  NaN\n",
      "744   1869   NaN  handsfree future is good , but not too exciting .  NaN\n",
      "745    890   NaN  12 ) big storage - my entire cd collection in ...  NaN\n",
      "746   1820   NaN    2 it is easy enough for my grandmother to use .  NaN\n",
      "747   2840   NaN                       controls are a bit awkward .  NaN\n",
      "748   1330   NaN  the documentation is much better than the docu...  NaN\n",
      "749   1935   NaN  nokia makes great phones , and this one is the...  NaN\n",
      "750   2529   NaN        after two weeks the picture kept freezing .  NaN\n",
      "751    827   NaN                                * removable battery  NaN\n",
      "752   3581   NaN  but i had to give you four because the service...  NaN\n",
      "753    215   NaN                           takes excellent photos .  NaN\n",
      "754    503   NaN  first , it really is tiny ; . the size of a pa...  NaN\n",
      "\n",
      "[3771 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3c) Convert all labels in CR_df[\"label\"] using the function we defined above \"convert_label\"\n",
    "#   Save these numerical labels as a new column named \"y\" in CR_df.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_df['y'] = CR_df[\"label\"].apply(convert_label)\n",
    "print(CR_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c913739a93d890af4fcde874cff4e29c",
     "grade": true,
     "grade_id": "A-3c",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_df['y'], pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7314af8d43852facb7ef4d132e75dee5",
     "grade": false,
     "grade_id": "Q-3d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3d) Transform reviews (CR_df[\"review\"]) into vectors using the \"tfidf\" vectorizer we created in part 2.\n",
    "#  Save the transformed data into a variable called \"CR_tfidf_X\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_tfidf_X = tfidf.fit_transform(CR_df[\"review\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52cb10ad2630ae497778efcbca1942fd",
     "grade": true,
     "grade_id": "A-3d",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_tfidf_X, np.ndarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "138fea75f0adbf13da2b77dfaea83b0e",
     "grade": false,
     "grade_id": "get_data",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we will collect all training samples & numerical labels from CR_tfidf_X [code provided]\n",
    "#   The code provided below will extract all samples with labels from the dataframe\n",
    "\n",
    "CR_train_X = CR_tfidf_X[~CR_df['y'].isnull()]\n",
    "CR_train_y = CR_df['y'][~CR_df['y'].isnull()]\n",
    "\n",
    "# Note: if these asserts fail, something went wrong\n",
    "#  Go back and check your code (in part 3) above this cell\n",
    "assert CR_train_X.shape == (3016, 2000)\n",
    "assert CR_train_y.shape == (3016, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e9e7c0c4d285e57c6c8188a514224973",
     "grade": false,
     "grade_id": "Q-3e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3e) Train an SVM classifier on the samples \"CR_train_X\" and the labels \"CR_train_y\"\n",
    "#   You need to call the function \"train_SVM\" you created above.\n",
    "#   Name the returned object as \"CR_clf\"\n",
    "#   Note that this function will take many seconds / up to a few minutes to run.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_clf = train_SVM(CR_train_X, CR_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a9250c5705606e504c15597175657ee",
     "grade": true,
     "grade_id": "A-3e",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_clf, SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "8a834bee035879fa45b08ad5a1b0fe8a",
     "grade": false,
     "grade_id": "Q-3f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3f) Predict labels on the training set, and name the returned variable as \"CR_pred_train_y\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_pred_train_y = CR_clf.predict(CR_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d0c54b282080ec83c81b76b537bc32de",
     "grade": false,
     "grade_id": "cell-5393293deccc9d78",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.90      0.84      0.87      1097\n",
      "        1.0       0.91      0.95      0.93      1919\n",
      "\n",
      "avg / total       0.91      0.91      0.91      3016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the classifier accuracy on the train data\n",
    "#   Note that your classifier should be able to reach above 90% accuracy.\n",
    "print(classification_report(CR_train_y, CR_pred_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dab7a4c970b847e5a97e5b5a7f4c6766",
     "grade": true,
     "grade_id": "A-3f",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests for 3f\n",
    "precision, recall, _, _ = precision_recall_fscore_support(CR_train_y, CR_pred_train_y)\n",
    "assert np.isclose(precision[0], 0.90, 0.02)\n",
    "assert np.isclose(precision[1], 0.91, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b5df6600b7e7dd3c737ecc0ee81a950",
     "grade": false,
     "grade_id": "cell-8fd0d23508a04891",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Collect all test samples from CR_tfidf_X\n",
    "CR_test_X = CR_tfidf_X[CR_df['y'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf54201786f3c9ae7652872f025447b5",
     "grade": false,
     "grade_id": "Q-3g",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 3g) Predict the labels on the test set. \n",
    "#  Name the returned variable as \"CR_pred_test_y\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "CR_pred_test_y = CR_clf.predict(CR_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c9ce7c1d4cf51848d1c73cd06a6269a2",
     "grade": true,
     "grade_id": "A-3g",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_X, np.ndarray)\n",
    "assert isinstance(CR_pred_test_y, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "853acea34db02c2bcffce847ee564b54",
     "grade": false,
     "grade_id": "Q-3h",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                             review label\n",
      "0     3546                                        its quiet .   pos\n",
      "1     3232  overall , it does its basic function very well...   pos\n",
      "2      979  i love that you don 't have to purchase expens...   pos\n",
      "3      372  i bought this camera two days ago , and i 'm v...   pos\n",
      "4     3278  it barely holds anything and mine just puts a ...   pos\n",
      "5     3683  now in october , 2004 , the firewall said i co...   pos\n",
      "6      742                  lastly , the price is fantastic :   pos\n",
      "7     3471  these people takes lest effort to process reba...   neg\n",
      "8     1509  i compared it to other cd players ( two models...   pos\n",
      "9     1079               i have never had an odor problem ! .   pos\n",
      "10    3753  buy this if you like mental challenges or tryi...   pos\n",
      "11     581  the screen is very easy to read and the blue l...   pos\n",
      "12    3589  first , let me say that i got the 20gb ipod fo...   pos\n",
      "13    2563  5 ) this apex model 2600 will not work with my...   neg\n",
      "14     419  neat feature for self-timer allows you to reco...   pos\n",
      "15    2133                   the phone is very light weight .   pos\n",
      "16    2240       this phone is highly recommended otherwise .   pos\n",
      "17    1605  pros the design is very nice , and the colors ...   pos\n",
      "18     895  i felt better with this one since it had the s...   pos\n",
      "19    3101  it 's oftentimes hard to get a good grip on th...   pos\n",
      "20    1724  nikon 4300 , i feel , is the best camera out t...   pos\n",
      "21    1771  the small size is perfect for my little hands ...   neg\n",
      "22    3400     even the instruction booklet is out of order .   neg\n",
      "23    3185  so , you might inquire , why don 't they make ...   neg\n",
      "24     787      oh . . . and file transfers are fast & easy .   pos\n",
      "25     616  i have over 2000 files in my playlist at the m...   pos\n",
      "26    3341  now , the player 's ear phone jack is not work...   neg\n",
      "27    1773  it really is an awesome camera that is hard to...   pos\n",
      "28    3096  that said , i am disappointed in the plunging ...   neg\n",
      "29    2771  i 've tried the belkin fm transmitter unit wit...   neg\n",
      "..     ...                                                ...   ...\n",
      "725   1761  if you have to buy a camera on a bu get , this...   pos\n",
      "726   1512             fits well in hand in trouser pockets .   pos\n",
      "727    771  it 's small , light and nice looking and the d...   pos\n",
      "728   3711  then , my ad/pop-up blocking was completely go...   neg\n",
      "729    248  4 . the shape of this device is a little squar...   pos\n",
      "730    891  7 ) some people have problems with the flip sw...   neg\n",
      "731   2249  sound quality : the ipod 's sound quality is p...   pos\n",
      "732   2346                                way to go apple ! .   pos\n",
      "733   1195                        smooth plunging mechanism .   neg\n",
      "734   2556  the front door is miss aligned on my unit and ...   neg\n",
      "735   1484                             the sound is amazing .   pos\n",
      "736   3769  this time , it started the installation proces...   neg\n",
      "737   2727        only 1 problem , no accessories . . . yet .   neg\n",
      "738   3738  to install that version you have to uninstall ...   neg\n",
      "739   1505  built in microphone is great for recording sho...   pos\n",
      "740   1395  creative did well on its rechargeable battery ...   pos\n",
      "741   3226  limitations : - not a lot of original accessor...   pos\n",
      "742    688                          1 ) price / gb of storage   pos\n",
      "743   1305  just follow the instructions carefully , it 's...   pos\n",
      "744   1869  handsfree future is good , but not too exciting .   neg\n",
      "745    890  12 ) big storage - my entire cd collection in ...   pos\n",
      "746   1820    2 it is easy enough for my grandmother to use .   pos\n",
      "747   2840                       controls are a bit awkward .   neg\n",
      "748   1330  the documentation is much better than the docu...   pos\n",
      "749   1935  nokia makes great phones , and this one is the...   pos\n",
      "750   2529        after two weeks the picture kept freezing .   neg\n",
      "751    827                                * removable battery   neg\n",
      "752   3581  but i had to give you four because the service...   pos\n",
      "753    215                           takes excellent photos .   pos\n",
      "754    503  first , it really is tiny ; . the size of a pa...   neg\n",
      "\n",
      "[755 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3h) Convert the predicted numerical labels back to string labels\n",
    "# Create a column called \"label\" in \"CR_test_df\" to store the converted labels\n",
    "\n",
    "# YOUR CODE HERE\n",
    "def num_to_str(label):\n",
    "    if label in [1.0]:\n",
    "        string = 'pos'\n",
    "    elif label in [0.0]:\n",
    "        string = 'neg'\n",
    "    else:\n",
    "        string = label\n",
    "    return string\n",
    "\n",
    "CR_test_df['label'] = CR_pred_test_y\n",
    "CR_test_df['label'] = CR_test_df['label'].apply(num_to_str)\n",
    "print(CR_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e32bdf404a55ba5453d5bbd05209560d",
     "grade": true,
     "grade_id": "A-3h",
     "locked": true,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(CR_test_df['label'], pd.Series)\n",
    "assert set(CR_test_df['label']) == {'neg', 'pos'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ca8ea811adcee4258c93c9684165cb9c",
     "grade": false,
     "grade_id": "cell-24356cb4367a5c1b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The hidden assignments tests for the cell above will check that your model predicts the right number of pos/neg reviews in the test data provided. \n",
    "\n",
    "We now have a model that can predict positive or negative sentiment! \n",
    "\n",
    "In the cell below, as a written answer question, briefly, in your own words, what BoW and TF/IDF word representations are, and how they differ. Also, think about and write a quick example of when and why it might be useful to automatically analyze the sentiment of text data. [This whole answer can/should be a couple sentences].\n",
    "\n",
    "After you answer this question, you arae done! Submit this notebook by uploading it to TritonED. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2fa8493f1dc08831d45aa221dc494dc2",
     "grade": true,
     "grade_id": "cell-bf8fe759022c76b4",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "BOW is the Bag of Words representations, as it takes the value and equally contributes to the weight while TF/IDF takes the average and compares it to the whole, to determine which group of words is more valued, rather than repeated. It would be useful to automatically analyze the sentiment of text data to determine its importance rather than wasting time reading data that might be biased or skewed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
